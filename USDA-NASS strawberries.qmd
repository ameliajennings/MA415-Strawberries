---
title: "MA415 Midterm Project"
date: "2025 March 6"
format: 
  html:
    embed-resources: true
editor: visual
---

# EDA: Preparing Strawberry data for analysis

Due: March 21

As described in class, this document is a starter for the Midterm project.

Your assignment is to clean, organize, and explore the data. Turn in a report that describes how your work has set the stage for further analysis and model building.

The dataset contains strawberry farming data with details about conventional and organic cultivation. These data include information about chemicals used in strawberry farming, as well as sales, revenue and expense details.

While there is no "right answer" for this assignment, there are characteristics for the report that are essential. For example, sata visualization is critical. So is producing tabular presentations and document structure. Your target audience consists of analysts who may take the next steps with the data analysis and modeling.

Think of your report as a stage on which to showcase your ability to use R to work with data and produce professional reports. This is an opportunity to do some data storytelling.

Submit your report on or before March 21 using the Midterm portal on Blackboard.

## Introduction: foundations

Before we begin to work with the strawberry data, let's talk about how we will approach the work.

### Data cleaning and organization

Cleaning and organizing data for analysis is an essential skill for data scientists. Serious data analyses must be presented with the data on which the results depend. The credibility of data analysis and modelling depends on the care taken in data preparation and organization.

#### References

In their handbook ["An introduction to data cleaning with R" by Edwin de Jonge and Mark van der Loo](https://cran.r-project.org/doc/contrib/de_Jonge+van_der_Loo-Introduction_to_data_cleaning_with_R.pdf), de Jonge and van der Loo go into detail about specific data cleaning isssues and how to handle them in R.

["Problems, Methods, and Challenges in Comprehensive Data Cleansing" by Heiko MÃ¼ller and Johann-Christoph Freytag](https://www.researchgate.net/profile/Heiko-Mueller/publication/228929938_Problems_methods_and_challenges_in_comprehensive_data_cleansing/links/09e415101b58541e2c000000/Problems-methods-and-challenges-in-comprehensive-data-cleansing.pdf) is a good companion to the de Jonge and van der Loo handbook, offering additional issues in their discussion.

### Attitudes

Mechanistic descriptions of data cleaning methods are insufficient.

#### Data is the product (or by-product) of purposeful human activity

Much of the data used in analysis accessed on local databases or online which may create the impression that the data have been carefully curated. Beware. Data are produced by people for a purpose, with a point-of-view, and at a time and location that may affect the data. The provenance and lineage of the data are meta data you should include when reporting analysis. Data collection is purposeful human activity with all of the risks and weaknesses that are part of any purposeful human activity.

#### Data is language

Data has meaning. Data can be included in sentences related to the meaning of the data. Cleaning and organizing data should be informed by the meaning the data convey and how that meaning relates to the research you are doing do achieve this important result.

-   Immerse yourself in the data. Put data into context.

-   Visualize the data to find problems, confirm your understandings, and plan your data organization. People do a bad job of seeing meaningful patterns in data but a good job of seeing patterns of all kinds when data are rendered as plots. As you product and show visualizations, ask your self and those who view your presentations, "what do you see?" and "what do you wonder?"

## Example: Strawberries

### Public information

[WHO says strawberries may not be so safe for you--2017March16](https://med.news.am/eng/news/13621/who-says-strawberries-may-not-be-so-safe-for-you.html)

[Pesticides + poison gases = cheap, year-round strawberries 2019March20](https://www.ewg.org/foodnews/strawberries.php)

[Multistate Outbreak of Hepatitis A Virus Infections Linked to Fresh Organic Strawberries-2022March5](https://www.cdc.gov/hepatitis/outbreaks/fresh-strawberries-2022/?CDC_AAref_Val=https://www.cdc.gov/hepatitis/outbreaks/2022/hav-contaminated-food/index.htm)

[Strawberry makes list of cancer-fighting foods-2023May31](https://issuu.com/mechlocal/docs/053123_mech_asf/s/25386339)

## What is the question?

-   Where they are grown? By whom?

-   Are they really loaded with carcinogenic poisons?

-   Are they really good for your health? Bad for your health?

-   Are organic strawberries carriers of deadly diseases?

-   When I go to the market should I buy conventional or organic strawberries?

## The data

The data set for this assignment has been selected from:

[strawberries 2025march6](https://va-dmz-quickstats.va-dmz-asev3.appserviceenvironment.us/results/B40FC8C0-E9E1-3F96-B259-DC65147DA53B)

<!-- and has been stored on the blackboard as strawberries25_v3.csv. -->

## USDA NASS

```{r}
#| label: load libraries
#| warning: false
#| message: false

library(knitr)  
library(kableExtra)
library(tidyverse)
library(stringr)
```

## Read the file

```{r}
#| label: read data - glimpse 


strawberry <- read_csv("strawb_mar6.csv", 
                       col_names = TRUE,
                       show_col_types = FALSE)

source("my_functions.R")

```

Examine the data. How is it organized?

```{r}

strawb <- strawberry |> drop_one_value_col()


```

```{r}
#| label: explore strawb data

# assume data is a tibble
# n_show is the number of rows to show



show_unique <- function(data, nrows=10 ){
  # make a tibble items to hold the data to show
  # browser()
  a <- nrows * dim(data)[2]  # number of cells in items
  items <- rep(" ", a) # items will coerce everything to char
  dim(items) <- c(nrows ,dim(data)[2]) # shape items
  items <- as_tibble(items)
  colnames(items) <- colnames(data)
  # browser()
  for(i in 1:dim(data)[2]){

    col_items <- unique(data[,i])
    # row_ex is the number of rows needed 
    # to make the column length conformable with items
    row_ex <- nrows - dim(col_items)[1] 
    if(row_ex >= 0){
      ex_rows <- tibble(rep(" ",row_ex))
      colnames(ex_rows) <- colnames(col_items)
      col_add <- rbind2(col_items, ex_rows)
      
    } else if(row_ex < 0){
      col_add <- col_items[1:10,]
      
    }

    items[,i] <- col_add

  }
  
  return(items)
}

## test <- show_unique(strawb, 10)


```

```{r}
#|label: split strawb into census and survey pieces

strw_census <- strawb |> filter(Program == "CENSUS")

strw_survey <- strawb |> filter(Program == "SURVEY")

nrow(strawb) == (nrow(strw_census) + nrow(strw_survey))

```

```{r}
#| label: examine Census and survey tibbles
#| warning: false


s_census <- strw_census |> drop_one_value_col(prt_val = TRUE)

s_survey <- strw_survey |> drop_one_value_col(prt_val = TRUE)


unique_sur <- s_survey |> show_unique(nrows = 10)

unique_cen <- s_census |> show_unique(nrows = 10)


strw_census <- s_census |> select(-`State ANSI`)

strw_survey <- s_survey |> select(-`State ANSI`, -`Week Ending`, -Period)

rm(s_census, s_survey, strawberry, strawb, items)


```

```{r}
#| label: work on Census columns

commod <- strw_census$Commodity |> unique()

#### split Data Item

strw_census <- strw_census |>
  separate_wider_delim(  cols = Commodity,
                         delim = ",",
                         names = c("INCOME", 
                                   "NET CASH FARM",
                                   "STRAW"
                                               ),
                         too_many = "error",
                         names_sep = " ",
                         too_few = "align_start"
  )



inc <- strw_census$Fruit |> unique()

strw_census <- strw_census |>
  separate_wider_delim(  cols = Fruit,
                         delim = ",",
                         names = c("INCOME", 
                                   "STRAWB"
                                               ),
                         too_many = "error",
                         too_few = "align_start"
  )

```

```{r}
#| label: Assignment shortner results

straw_cen_f <- strw_census |> filter(State == "FLORIDA")

straw_sur_f <- strw_survey |> filter(State == "FLORIDA")
straw_cen_c <- strw_census |> filter(State == "CALIFORNIA")
straw_sur_c <- strw_survey |> filter(State == "CALIFORNIA")

rm(strw_census, strw_survey, unique_cen, unique_sur)

```

# Chemical Treatments Analysis

### Begin with combining survey data

#### I want to use the survey data, specifically, in order to do an analysis that compares the usage of three chemicals across states and across years.

```{r}
#| label: combine-survey-data
#| echo: false

# combine the ca and fl survey data
chemicals_df <- bind_rows(straw_sur_c, straw_sur_f)

print(head(chemicals_df))
```

#### I want to find what chemicals there are so I can narrow down what is suitable for analysis

```{r}
#| label: extract chemical names
#| echo: true

# extract chemical names from the 'Domain Category' field
chemicals_df <- chemicals_df |>
  mutate(Chemical = str_extract(`Domain Category`, "\\((.*?)\\)")) |>
  mutate(Chemical = str_replace_all(Chemical, "[()]", "")) |>
  mutate(Chemical = str_trim(Chemical))

# unique chemicals to verify extraction
unique_chemicals <- unique(chemicals_df$Chemical)
print(unique_chemicals)

```

### Filtering for valid chemicals

```{r}
#| label: filter valid chemicals
#| echo: false

chemicals_df <- chemicals_df |>
  filter(!is.na(Chemical) & Chemical != "")

print(head(chemicals_df, 10))

```

### To compare usage, I need to remove values that have (D) or (NA) so that there are not any unsuitable entries being used. Since we are only comparing 3 different chemicals, I would like all 3 of them to have number values to get a meaningful insight.

```{r}
#| label: filter valid values
#| echo: false

# filter out where the Value column contains (D) or (NA)
chemicals_df <- chemicals_df |>
  filter(!is.na(Value) & !Value %in% c("(D)", "(NA)"))

print(head(chemicals_df, 10))
```

### Here, I want to isolate the name of the chemicals being used from the 'Chemical' column in chemicals_df from the numbers so I can later filter through based just on chemical name.

```{r}
#| label: isolate names in chemicals column
#| echo: false

# isolate just the names
chemicals_df <- chemicals_df |> 
  mutate(Chemical = str_extract(Chemical, "^[^=]+")) |>  # extract everything before '='
  mutate(Chemical = str_trim(Chemical))

unique_chemicals <- chemicals_df |> distinct(Chemical)
print(unique_chemicals)
```

### Here, I am looking chemicals that will fit the criteria that I want for my analysis. I want chemicals that have records both in California and Florida so there is not any missing data when making visualizations.

```{r}
#| label: valid chemicals to use in analysis
#| echo: false

valid_chems <- chemicals_df |> 
  group_by(Chemical, State, Year) |> 
  summarize(Count = n(), .groups = "drop") |> 
  group_by(Chemical) |> 
  summarize(
    CA = sum(State == "CALIFORNIA"),
    FL = sum(State == "FLORIDA")
  ) |> 
  filter(CA == 2 & FL == 2) |>  # ca and fl should have data for both years
  pull(Chemical)

print(valid_chems)
```

### Now that I have a list of viable options, I chose Abamectin, Fludioxonil, and Thiram to compare across the two states. This is a summary, mostly to make sure that I have 12 records like I expect.

```{r}
#| label: abamectin, fludioxonil, and thiram summary
#| echo: true

# no commas and converting to numeric
chemicals_df <- chemicals_df |>
  mutate(Value = as.numeric(gsub(",", "", Value)))

selected_chems <- c("ABAMECTIN", "FLUDIOXONIL", "THIRAM")

# summarize by year and state
chemical_summary <- chemicals_df |>
  filter(Chemical %in% selected_chems) |>
  group_by(Year, State, Chemical) |>
  summarize(Total_Use_Lbs = sum(Value, na.rm = TRUE), .groups = "drop")

print(chemical_summary)

```

## Total Use of Selected Chemicals by State and Year

```{r}
#| label: make plot
#| echo: true

ggplot(chemical_summary, aes(x = Chemical, y = Total_Use_Lbs, fill = State)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Year) +
  labs(title = "Total Use of Selected Chemicals by State and Year",
       x = "Chemical",
       y = "Total Use (lbs)") +
  theme_minimal()
```

## Chemical Usage from 2021 to 2023 by State

### Useage from 2021 to 2023 can be seen here. It seens like in both California and Florida, useage for Abamectin and Fludioxonil went up between from 2021 to 2023. However, Thiram useage went up for California went up while it went down for Florida. I hypothesize this is due to an alternative fungicide that does a better job that replaced Florida's use of Thiram.

```{r}
#| label: did usage go up or down from 2021 to 2023?
#| echo: true

ggplot(chemical_summary, aes(x = Year, y = Total_Use_Lbs, color = State, group = State)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  geom_text(aes(label = round(Total_Use_Lbs, 1)), vjust = -0.5, size = 3) +
  facet_wrap(~ Chemical, scales = "free_y") +
  labs(title = "Chemical Usage from 2021 to 2023 by State",
       x = "Year",
       y = "Total Use (lbs)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
        axis.text.y = element_text(size = 10),
        plot.title = element_text(size = 14, face = "bold"))
```

# Analysis on Production & Sales of Different Types of Strawberries

```{r}
#| label: combine straw census data for florida and california
#| echo: false
straw_data <- bind_rows(straw_cen_c, straw_cen_f)

straw_clean <- straw_data |>
  mutate(Value = suppressWarnings(as.numeric(gsub(",", "", trimws(Value))))) |>
  filter(!is.na(Value))

```

```{r}
#| echo: false
straw_only <- straw_clean |> 
  filter(`Commodity INCOME` == "STRAWBERRIES")
```

```{r}
#| label: add labels for processing/fresh and organic/conventional
#| echo: false
straw_typed <- straw_only |>
  mutate(
    Market_Type = case_when(
      str_detect(Item, regex("FRESH", ignore_case = TRUE)) ~ "Fresh Market",
      str_detect(Item, regex("PROCESSING", ignore_case = TRUE)) ~ "Processing",
      TRUE ~ "Other"
    ),
    Organic_Status = case_when(
      str_detect(Domain, regex("ORGANIC", ignore_case = TRUE)) ~ "Organic",
      TRUE ~ "Conventional"
    )
  )
```

```{r}
#| label: separate price and volume
#| echo: false
price_data <- straw_typed |> 
  filter(str_detect(Metric, "\\$"))  #price data

volume_data <- straw_typed |>
  filter(str_detect(Metric, "CWT"))  #volume data
```

```{r}
#| label: summaries
#| echo: false
library(scales)

price_summary <- price_data |> 
  group_by(Year, State, Market_Type, Organic_Status) |> 
  summarize(Reported_Price = sum(Value, na.rm = TRUE), .groups = "drop")

volume_summary <- volume_data |> 
  group_by(Year, State, Market_Type, Organic_Status) |> 
  summarize(Reported_Volume = sum(Value, na.rm = TRUE), .groups = "drop")
```

```{r}
#| label: plot for strawberry volumes by market type and state
#| echo: true
ggplot(volume_summary, aes(x = Year, y = Reported_Volume, fill = Organic_Status)) +
  geom_col(position = "dodge") +
  facet_grid(State ~ Market_Type) +
  labs(
    title = "Reported Strawberry Volumes by Market Type and State",
    y = "Reported Volume (CWT)",
    x = "Year"
  ) +
  theme_minimal()
```

### Based on the USDA census data, strawberries for both California and Florida were mostly organic production. Florida shows more distribution across different categories including processing.
